{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271af8e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import os\n",
    "# import h5py\n",
    "import pickle\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ee43a883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2']\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "path='DataSet'\n",
    "# filename=os.listdir(\"DataSet\")\n",
    "for fileName in os.listdir(path):\n",
    "    f = os.path.join(path, fileName)\n",
    "    images = os.listdir(f)\n",
    "    for i in images:\n",
    "#     image=Image.open('0/'+i).convert('L')\n",
    "        image=Image.open(f+'/'+ i)\n",
    "        image=image.resize((256,256))\n",
    "        image=np.array(image)\n",
    "        data.append(image)\n",
    "        labels.append(fileName)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5f14031e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "#Converting lists into numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f329b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaish_2\\AppData\\Local\\Temp\\ipykernel_19052\\1136154699.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  labels = labels.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "labels = labels.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7ac78856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data,dtype='float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "954ed8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e45d9187",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6528286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for a in y_test:\n",
    "  print(np.argmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "19cc4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid= train_test_split(\n",
    "    X_train, y_train, test_size=.05, random_state=1234,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a92055e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_categorical Converts a class vector (integers) to binary class matrix.\n",
    "y_train = to_categorical(y_train,3)\n",
    "y_valid = to_categorical(y_valid,3)\n",
    "y_test = to_categorical(y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "32319af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 256, 256, 3)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "38174022",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=x_train.shape[1:]))\n",
    "cnn_model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Dropout(rate=0.25))\n",
    "cnn_model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Dropout(rate=0.25))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(256, activation='relu'))\n",
    "cnn_model.add(Dropout(rate=0.5))\n",
    "cnn_model.add(Dense(3, activation='softmax'))\n",
    "# Here also we have changed above to 1 instead of previous 41\n",
    "\n",
    "#Compilation of the model\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "583651de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 252, 252, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 248, 248, 32)      25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 124, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 124, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 122, 122, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 120, 120, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 230400)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               58982656  \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 59,066,915\n",
      "Trainable params: 59,066,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "25f0b6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 - 6s - loss: 1.1182 - accuracy: 0.3333 - val_loss: 3.0974 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 - 4s - loss: 5.0650 - accuracy: 0.4667 - val_loss: 0.2123 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 - 3s - loss: 4.0507 - accuracy: 0.3333 - val_loss: 0.9597 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 - 2s - loss: 1.4293 - accuracy: 0.5333 - val_loss: 1.0814 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 - 2s - loss: 0.9284 - accuracy: 0.5333 - val_loss: 1.1095 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 - 2s - loss: 0.9835 - accuracy: 0.9333 - val_loss: 1.0831 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 - 2s - loss: 0.8251 - accuracy: 0.9333 - val_loss: 1.0352 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 - 2s - loss: 0.4625 - accuracy: 1.0000 - val_loss: 1.0175 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 - 2s - loss: 0.5015 - accuracy: 0.7333 - val_loss: 0.3663 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 - 2s - loss: 0.3568 - accuracy: 0.9333 - val_loss: 0.2546 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 - 2s - loss: 0.2843 - accuracy: 0.9333 - val_loss: 0.6966 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 - 2s - loss: 0.6101 - accuracy: 0.8667 - val_loss: 0.0645 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 - 2s - loss: 0.1441 - accuracy: 0.8667 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 - 2s - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 - 2s - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 - 2s - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 - 2s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 - 2s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 - 2s - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 - 2s - loss: 0.1019 - accuracy: 0.9333 - val_loss: 0.1490 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 - 2s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 - 2s - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 - 2s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 - 2s - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 - 2s - loss: 0.1202 - accuracy: 0.9333 - val_loss: 0.1778 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0242 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 - 2s - loss: 3.5871e-05 - accuracy: 1.0000 - val_loss: 1.9965 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 - 2s - loss: 0.1236 - accuracy: 0.9333 - val_loss: 0.1522 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history=cnn_model.fit(\n",
    "    np.array(x_train), np.array(y_train), batch_size=512,\n",
    "    epochs=30, verbose=2,\n",
    "    validation_data=(np.array(x_valid),np.array(y_valid)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "608e7557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test los 0.0198\n",
      "test acc 1.0000\n"
     ]
    }
   ],
   "source": [
    "scor = cnn_model.evaluate( np.array(x_test),  np.array(y_test), verbose=0)\n",
    "\n",
    "print('test los {:.4f}'.format(scor[0]))\n",
    "print('test acc {:.4f}'.format(scor[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "550d136e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001A6E1DF1670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001A6E1DF1670>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001A6E1DF1670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001A6E1DF1670>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# # save the model to disk\n",
    "# filename = 'finalized_model.sav'\n",
    "# pickle.dump(cnn_model, open(filename, 'wb'))\n",
    "\n",
    "cnn_model.save('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "093a5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "676ee020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "image=\"ImagesCropped/0/0.jpg\"\n",
    "image1=\"DataSet/2/0.jpg\"\n",
    "outside=\"V/0.jpg\"\n",
    "image=Image.open(outside)\n",
    "image=image.resize((256,256))\n",
    "# image=np.array(image)\n",
    "image = np.array(image,dtype='float32')/255\n",
    "# image=image.resize(-1,256,256,3)\n",
    "\n",
    "image= tf.expand_dims(image, axis =0)\n",
    "# image.shape\n",
    "# print(image)\n",
    "# ans=cnn_model.predict(image)\n",
    "ans=reconstructed_model.predict(image)\n",
    "ans=ans.tolist()\n",
    "listv = ans[0]\n",
    "n = listv.index(max(listv))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c9d678da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"info.csv\")\n",
    "name=df.loc[df.sr == n,'Name'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c0772ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 04:09:50\n",
      "year: 2022\n",
      "month: 04\n",
      "day: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"time:\", time)\n",
    "\n",
    "year = now.strftime(\"%Y\")\n",
    "print(\"year:\", year)\n",
    "\n",
    "month = now.strftime(\"%m\")\n",
    "print(\"month:\", month)\n",
    "\n",
    "day = now.strftime(\"%d\")\n",
    "print(\"day:\", day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a05ee34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                Vaish\n",
      "Clock In Time    04:09:50\n",
      "Date             12042022\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rec=pd.read_csv(\"Record.csv\")\n",
    "list=[]\n",
    "# list=[name,time,day+month+year]\n",
    "list.append(name)\n",
    "list.append(time)\n",
    "list.append(day+month+year)\n",
    "row=pd.Series(list,index=['Name','Clock In Time','Date'])\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "169edefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaish_2\\AppData\\Local\\Temp\\ipykernel_19052\\1950223412.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  rec=rec.append(row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "rec=rec.append(row, ignore_index=True)\n",
    "rec.to_csv(\"Record.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "545f8cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path=\"DataSet\"\n",
    "count=len(os.listdir(path))\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
